import streamlit as st
import os
import google.generativeai as genai

# --- 1. é…ç½®é¡µé¢ ---
st.set_page_config(
    page_title="é¾™æ–‡ä¸­æ–‡å­¦æ ¡ - HSK1 è¯­æ³•æŒ‘æˆ˜",
    page_icon="ğŸ²",
    layout="centered"
)

# --- 2. è·å– API Key ---
api_key = os.environ.get("GOOGLE_API_KEY")

if not api_key:
    st.error("âš ï¸ æœªæ£€æµ‹åˆ° API Keyã€‚è¯·åœ¨ Render åå°è®¾ç½®ã€‚")
    st.stop()

# --- 3. åˆå§‹åŒ–æ¨¡å‹ ---
genai.configure(api_key=api_key)

# æ ¸å¿ƒæŒ‡ä»¤
SYSTEM_PROMPT = """
ä½ æ˜¯â€œé¾™æ–‡ä¸­æ–‡å­¦æ ¡â€çš„ HSK1 ä¸“å±åŠ©æ•™ã€‚
ç›®æ ‡ï¼šå¼•å¯¼å­¦ç”Ÿå®Œæˆ Unit 11 è¯­æ³•æŒ‘æˆ˜ã€‚
è§„åˆ™ï¼š
1. å§‹ç»ˆå…ˆç»™å‡ºä¸€ä¸ªç¿»è¯‘æŒ‘æˆ˜ï¼ˆä¸­/è‹±/è¥¿è‡ªé€‚åº”ï¼‰ã€‚
2. åšå¯¹æ—¶è¡¨æ‰¬è¯­åºã€‚
3. åšé”™æ—¶å¼•ç”¨è€å¸ˆçš„è§„åˆ™å¼•å¯¼ã€‚
4. ä¸¥ç¦ä½¿ç”¨ Unit 11 ä¹‹åçš„è¯æ±‡ã€‚
"""

# é…ç½®å‚æ•°
generation_config = {
    "temperature": 0.7,
    "max_output_tokens": 2048,
}

# --- å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨è¯Šæ–­åˆ—è¡¨ä¸­ç¡®è®¤å¯ç”¨çš„ 2.0 æ¨¡å‹ ---
try:
    model = genai.GenerativeModel(
        model_name="gemini-2.0-flash", 
        generation_config=generation_config,
        system_instruction=SYSTEM_PROMPT
    )
except Exception as e:
    st.error(f"æ¨¡å‹é…ç½®é”™è¯¯: {e}")
    st.stop()

# --- 4. ç•Œé¢é€»è¾‘ ---
st.title("ğŸ² é¾™æ–‡ HSK1 è¯­æ³•æŒ‘æˆ˜è€…")

if "messages" not in st.session_state:
    st.session_state.messages = []
    try:
        chat = model.start_chat(history=[])
        st.session_state.chat_session = chat
        # ä¸»åŠ¨è§¦å‘å¼€åœºç™½
        response = chat.send_message("Please start the challenge now.")
        st.session_state.messages.append({"role": "assistant", "content": response.text})
    except Exception as e:
        st.error(f"è¿æ¥å¤±è´¥: {e}")

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

if prompt := st.chat_input("è¯·è¾“å…¥ä½ çš„ç­”æ¡ˆ..."):
    st.chat_message("user").markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        try:
            response = st.session_state.chat_session.send_message(prompt)
            st.markdown(response.text)
            st.session_state.messages.append({"role": "assistant", "content": response.text})
        except Exception as e:
            st.markdown(f"å‡ºé”™å•¦: {e}")
